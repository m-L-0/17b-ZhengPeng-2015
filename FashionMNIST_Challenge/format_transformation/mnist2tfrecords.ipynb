{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/env/bin python3\n",
    "\n",
    "\"\"\"Convert MNIST Dataset to local TFRecords\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "def _data_path(data_directory: str, name: str) -> str:\n",
    "    \"\"\"Construct a full path to a TFRecord file to be stored\n",
    "    in the data_directory. Will also ensure the data directory exists\n",
    "\n",
    "    Args:\n",
    "        data_directory: The directory where the records will be stored\n",
    "        name:           The name of the TFRecord\n",
    "\n",
    "    Returns:\n",
    "        The full path to the TFRecord file\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    return os.path.join(data_directory, '{}.tfrecords'.format(name))\n",
    "\n",
    "\n",
    "def _int64_feature(value: int) -> tf.train.Features.FeatureEntry:\n",
    "    \"\"\"Create a Int64List Feature\n",
    "\n",
    "    Args:\n",
    "        value: The value to store in the feature\n",
    "\n",
    "    Returns:\n",
    "        The FeatureEntry\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature(value: str) -> tf.train.Features.FeatureEntry:\n",
    "    \"\"\"Create a BytesList Feature\n",
    "\n",
    "    Args:\n",
    "        value: The value to store in the feature\n",
    "\n",
    "    Returns:\n",
    "        The FeatureEntry\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def convert_to(data_set, name: str, data_directory: str, num_shards: int=1):\n",
    "    \"\"\"Convert the dataset into TFRecords on disk\n",
    "\n",
    "    Args:\n",
    "        data_set:       The MNIST data set to convert\n",
    "        name:           The name of the data set\n",
    "        data_directory: The directory where records will be stored\n",
    "        num_shards:     The number of files on disk to separate records into\n",
    "    \"\"\"\n",
    "\n",
    "    print('\\nProcessing {} data'.format(name))\n",
    "\n",
    "    images = data_set.images\n",
    "    labels = data_set.labels\n",
    "\n",
    "    num_examples, rows, cols, depth = data_set.images.shape\n",
    "\n",
    "    def _process_examples(start_idx: int, end_index: int, filename: str):\n",
    "        with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "            for index in range(start_idx, end_index):\n",
    "                sys.stdout.write(\"\\rProcessing sample {} of {}\".format(\n",
    "                    index+1, num_examples))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "                image_raw = images[index].tostring()\n",
    "                example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                    'height': _int64_feature(rows),\n",
    "                    'width': _int64_feature(cols),\n",
    "                    'depth': _int64_feature(depth),\n",
    "                    'label': _int64_feature(int(labels[index])),\n",
    "                    'image_raw': _bytes_feature(image_raw)\n",
    "                }))\n",
    "                writer.write(example.SerializeToString())\n",
    "            \n",
    "    if num_shards == 1:\n",
    "        _process_examples(0, data_set.num_examples,\n",
    "                          _data_path(data_directory, name))\n",
    "    else:\n",
    "        total_examples = data_set.num_examples\n",
    "        samples_per_shard = total_examples // num_shards\n",
    "\n",
    "        for shard in range(num_shards):\n",
    "            start_index = shard * samples_per_shard\n",
    "            end_index = start_index + samples_per_shard\n",
    "            _process_examples(start_index, end_index,\n",
    "                              _data_path(data_directory,\n",
    "                                         '{}-{}'.format(name, shard+1)))\n",
    "\n",
    "\n",
    "def convert_to_tf_record(data_directory: str):\n",
    "    \"\"\"Convert the TF MNIST Dataset to TFRecord formats\n",
    "\n",
    "    Args:\n",
    "        data_directory: The directory where the TFRecord files should be stored\n",
    "    \"\"\"\n",
    "\n",
    "    mnist = input_data.read_data_sets(\n",
    "        \"../MNIST_data/fashion\",\n",
    "        reshape=False\n",
    "    )\n",
    "\n",
    "    convert_to(mnist.validation, 'validation', data_directory)\n",
    "    convert_to(mnist.train, 'train', data_directory, num_shards=1)\n",
    "    convert_to(mnist.test, 'test', data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/fashion/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Processing validation data\n",
      "Processing sample 1084 of 5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/a/.virtualenvs/tf_cv_cuda8_cudnn6_geforce940m/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-f572fe12f6a1>\", line 6, in <module>\n",
      "    convert_to_tf_record(os.path.expanduser(data_directory))\n",
      "  File \"<ipython-input-8-076b5c2cd8e1>\", line 114, in convert_to_tf_record\n",
      "    convert_to(mnist.validation, 'validation', data_directory)\n",
      "  File \"<ipython-input-8-076b5c2cd8e1>\", line 89, in convert_to\n",
      "    _data_path(data_directory, name))\n",
      "  File \"<ipython-input-8-076b5c2cd8e1>\", line 83, in _process_examples\n",
      "    'image_raw': _bytes_feature(image_raw)\n",
      "  File \"<ipython-input-8-076b5c2cd8e1>\", line 50, in _bytes_feature\n",
      "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/a/.virtualenvs/tf_cv_cuda8_cudnn6_geforce940m/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/a/.virtualenvs/tf_cv_cuda8_cudnn6_geforce940m/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/a/.virtualenvs/tf_cv_cuda8_cudnn6_geforce940m/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/a/.virtualenvs/tf_cv_cuda8_cudnn6_geforce940m/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 669, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/a/.virtualenvs/tf_cv_cuda8_cudnn6_geforce940m/lib/python3.5/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    data_directory = '../MNIST_data/fashion/tfrecords'\n",
    "\n",
    "    convert_to_tf_record(os.path.expanduser(data_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
